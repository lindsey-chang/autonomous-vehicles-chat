**1 基于模块化设计的经济可靠的自动驾驶方案**

**1.1 简介**

近年来，自动驾驶已经成为科研界，工业界，乃至于新闻界的一个相当热门的话题，将基于自动驾驶技术的无人车投入人们日常生活中使用，这无疑是一场激动人心的变革。但是，除此之外，我们为什么要投入使用自动驾驶车辆呢？其中一个原因是，投入使用采用清洁能源的共享自动驾驶车辆可以减少环境污染，缓解交通拥堵，提高公路安全，促进经济高效发展，从而为我们的交通运输业带来颠覆性的改善。

更为具体地说，首先在减少环境污染方面：现在，美国现约有2.6亿辆汽车。根据美国能源部的研究，如果我们将所有的汽车转换为清洁能源汽车，每年可减少8亿吨的碳排放量，这将占美国对《巴黎协定》承诺的13.3%[1]。此外，如果共享自动驾驶车辆可以投入使用，并通过MIT计算机科学与人工智能实验室（CSAIL）研发的共享汽车调度系统进行调度，在最好的情况下可以减少约75%的城市汽车数量[2]。因此，综合上述两点，若广泛使用采用清洁能源的共享自动驾驶车辆，每年可减少10亿吨的碳排放量，这大约相当于美国对《巴黎协定》承诺的20%。

在提高公路安全方面，由人类司机驾驶的车辆的车祸率为每百万英里（per million miles, PMM）4.2起，而目前的自动驾驶车辆的车祸率为每百万英里（PMM）3.2起。并且，随着自动驾驶车辆安全性的不断提升，如果自动驾驶车辆的车祸率能降至每百万英里（PMM）1起以下，那么仅仅在美国每年就能挽救多达3万人的生命[4]。

最后，我们考虑共享自动驾驶车辆对经济的影响。每吨碳排放对美国GDP的影响约为220美元。这意味着，如果将所有的车辆转换为使用清洁能源的共享自动驾驶车辆，每年可以节省2200亿美元[5]。此外，由于在美国平均每发生一次车祸就会造成约3万美元的损失，通过使用自动驾驶车辆我们可以将车祸率降至每百万英里（PMM）1起以下，从而可以每年再减少3000亿美元的损失[6]。因此，仅仅在美国，如果广泛地推广采用清洁能源的共享自动驾驶车辆，每年就可节省多达5200亿美元，这几乎与世界上最大经济体之一瑞典的国内生产总值（GDP）相当。

虽然投入使用自动驾驶车辆有着各种各样的好处，但是现在将自动驾驶车辆大规模投入使用还面临着一些难题。其中包括技术可靠性问题、伦理和法律方面的问题，以及最重要的经济成本方面的问题。要成功构建一辆自动驾驶汽车并将其大规模地投入使用，我们还有哪些问题亟待解决？如何解决这些问题？在回答这些问题前，我们需要先了解自动驾驶车辆的底层设计。

**1.2 成本昂贵的自动驾驶技术**

在本节中，我们对现有自动驾驶系统的成本构成进行了分解，并证明了目前大规模部署自动驾驶系统的主要障碍是因为传感器（sensor）、计算系统（computing system）和高精度（High-Definition，HD）地图的成本过于昂贵[7]，如图1.1所示。

![图片](Aspose.Words.ca6e8170-2d72-4fa3-b069-82d5af9fff97.001.jpeg)

图1.1 现有自动驾驶解决方案的成本构成分解

在上面的图1.1中，右侧的文字为：大于100000美元的传感器硬件成本（> $100 000 USD sensing hardware cost），大于30000美元的计算系统硬件成本（> $30 000 USD computing hardware cost），数百万美元被用于创建和维护一张高精度地图（Millions of USD to create and maintain an HD map）。左侧箭头内的文字依次为：原始数据（Raw Data），点云数据（Point Clouds），点云对齐（Point Cloud Alignment），二维反射图（2D Reflectance Map），高精度地图标注（HD Map labeling），高精度地图（High Precision Map）。左侧箭头下方的文字为：高精度地图的制作流水线（HD Map Production Pipeline）。

**1.2.1 传感器系统**

自动驾驶中使用的主流传感器包括全球卫星导航系统（GNSS）、激光探测和测距系统（LiDAR，又称激光雷达）、车载摄像头、雷达（radar）和声呐（sonar）：全球卫星导航系统（GNSS）接收器，特别是那些具有实时动态定位（ real‐time kinematic，RTK）能力的接收器，GNSS接收器通过以至少米量级的精度更新车辆的全球位置，帮助自动驾驶车辆进行定位。但是，用于自动驾驶系统的高端GNSS接收器的价格可能远远超过1万美元。

激光雷达（LiDAR）是用于创建高精度地图、进行实时定位以及躲避障碍物的常用传感器。LiDAR的工作原理是激光器产生并发射一束光脉冲，打在物体表面并反射回来，最终光脉冲被接收器所接收，接收器准确地测量光脉冲从发射到被反射回的传播时间以确定自身与物体表面的距离。但是，激光雷达设备目前存在两个问题：第一，它们非常昂贵（一个可用于自动驾驶的激光雷达的价格可能超过8万美元）；第二，在恶劣的天气条件下，比如雨雾天气，它们可能无法提供准确的测量结果。

车载摄像头主要用于目标识别和追踪任务，例如识别车辆行驶环境中的车道线、交通灯和行人。为了实现这些任务，当前的解决方案通常是在车辆周围安装多个摄像头用于检测、识别和追踪物体。然而，车载摄像头存在一个致命缺点，就是在恶劣的天气条件下，其提供的图像数据可靠度较低。此外，自动驾驶车辆上的多个摄像头需要传输海量图像数据，因此对系统的计算能力也有着很高的要求。需要注意的是，这些摄像头的快门速度通常为60赫兹，以上情况结合起来，自动驾驶车辆的车载摄像头系统每秒可以产生超过1GB的原始数据。

雷达（radar）和声呐（sonar）：雷达和声呐系统是自动驾驶车辆用于躲避障碍物的最后一道防线。雷达和声呐产生的数据集显示了车辆行驶路径上距离最近的物体的距离。值得注意的是，雷达的主要优势是它在所有天气情况下都能正常工作。在通常情况下，声呐可以覆盖0到10米的范围，而雷达则可以覆盖3到150米的范围。这类传感器相对便宜，它们的成本加起来不到5000美元。

**1.2.2 高精度地图的创建和维护**

传统的数字地图通常由卫星图像生成，并且具有米量级的精度。虽然这一精度对于人类驾驶员来说已经绰绰有余，但是自动驾驶车辆需要更高精度的地图来提供车道（lane-level）级别的信息。因此，自动驾驶技术需要使用高精度地图（HD map）。

与传统的数字地图相似，高精度地图也具有分层的数据结构。其底层地图没有使用卫星图像，而是通过激光雷达（LiDAR）探测到的原始数据生成栅格地图（grid map），栅格地图的分辨率大约为5×5厘米。每个栅格中记录了单元环境中对象基本的高程和反射信息。自动驾驶车辆在行驶过程中，将车辆上激光雷达（LiDAR）新收集到的扫描数据与由全球卫星导航系统（GNSS）提供的初始位置估计得到的栅格地图进行实时比对，就能确定自身位置[8] 。

除了底层的栅格地图，高精度地图还包含其他几层语义信息地图。例如，在栅格地图的基础上，高精度地图一般还包含道路标志线的位置及特征信息，以及相应的车道特征，使得自动驾驶车辆可以准确地判断自己是否在正确的车道上行驶。此外，高精度地图相比传统数字地图还增加了交通标志牌信息，以告知自动驾驶车辆当地的限速情况，附近是否有交通信号灯等信息，为车辆提供额外的保护，这在自动驾驶车辆的传感器没有能成功检测出交通标志牌时尤其有用。

传统数字地图的更新周期一般为6到12个月。但为了确保高精度地图包含最新的信息，高精度地图的应该至少每周就更新一次。因此，对于存有一个中型城市信息的高精度地图，它的创建、运行和维护费用每年可能超过数百万美元。

**1.2.3 计算系统**

规划与控制算法和目标识别与追踪算法具有非常不同的行为特征，因此需要使用不同类型的处理器。此外，高精度地图（HD map）对内存有着较高的要求[9]。因此，必须在有限的计算资源和功率预算内设计一个能够满足这些需求的硬件计算系统。 如文献[9]所述，早期设计的自动驾驶计算系统配备了英特尔至强E5处理器和4到8颗英伟达 K80图形处理单元（GPU）加速器，这些处理器之间彼此使用PCI-E总线连接。虽然整个系统能够提供每秒64.5Tera次操作（64.5 TOP/S）的峰值运算能力，但它消耗了3000W的能量，这也导致了大量的热量产生。此外，整个解决方案的成本约为3万美元，这对于普通消费者来说是一个无法接受，并且根本负担不起的价格。

**1.3 实现经济可行性和技术可靠性**

许多知名的无人驾驶公司，如Waymo、百度和Uber，以及一些其他的公司都在参与一场从设计，到部署，再到最终普及自动驾驶车辆的竞争。自动驾驶车辆必须满足经济实用和安全可靠的要求，即使在最复杂的环境下也要能够安全驾驶。然而，正如上文所述，所有传感器的成本总和可能超过10万美元，计算系统的成本又是3万美元，这导致每辆车的成本非常高：一辆演示用的自动驾驶车的成本甚至可以轻松超过80万美元[10]。此外，除了单位成本之外，我们还尚不清楚如何支付高精度地图创建和维护的运营费用。

即使使用最先进的传感器，让自动驾驶车辆在复杂的交通环境下与人类驾驶的汽车共存仍然是一个棘手的问题。因此，如果未来几年不能显著降低传感器、计算系统和高精度地图的成本，并显著改善定位、感知和决策算法，自动驾驶技术将不会被普及。

为了解决这些问题，我们开发了一种应用于低速场景的可靠的自动驾驶车辆，例如用于大学校园、工业园区和交通不便的地区[11,12]。我们先从低速场景开始，以确保自动驾驶车辆的安全性，从而允许开发的车辆立即部署和投入使用。然后，随着技术的改进和经验的积累，我们将设想高速场景，并最终使自动驾驶车辆在任何驾驶场景中的表现与人类驾驶员表现相当。实现自动驾驶车辆经济和技术的可行性，关键在于使用传感器融合、模块化设计和高精度视觉地图（HPVMs）。

**1.3.1 传感器融合**

使用激光雷达（LiDAR） 进行定位或感知非常昂贵，而且得到的结果可能不可靠。为了综合考虑价格和技术因素，可以使用多个经济实惠的传感器，如摄像头，GNSS 接收器，车轮编码器，雷达和声呐，来协同融合它们的数据。这些传感器不仅有各自的特点、缺点和优势，而且它们可以互为补充。因此，当一个传感器失效或发生其他故障时，另外的传感器可以立即接管故障传感器的功能，从而确保系统的可靠性。通过这种传感器融合方法，自动驾驶车辆的传感器成本可以被控制在2000美元以内。



定位子系统依靠全球导航卫星系统（GNSS）接收器提供具有亚米级精度的初始定位。视觉里程计（visual odometry）可以进一步将定位精度提高到分米级。此外，在GNSS接收器和摄像头发生故障的情况下，可以使用车轮编码器来跟踪车辆的运动。视觉里程计通过检查两帧之间的重叠来推断位置变化。然而，当车辆突然运动时，例如急转弯，由于两个连续帧之间缺少重叠区域，视觉里程计可能无法保持定位。



主动感知子系统旨在帮助车辆了解其所在环境。基于这种理解，结合计算机视觉和毫米波（mmWave）雷达来探测和跟踪50米范围内的静态或移动物体，车辆可以根据探测结果做出行动决策，以确保行程的平稳和安全。借助双目视觉，不仅可以轻松地识别出包括行人和移动的车辆在内的物体，还可以准确地确定与这些物体之间的距离。此外，毫米波雷达还可以在所有天气条件下完成快速移动物体的检测和跟踪，并能够实时测量出自身和快速移动物体之间的距离。



被动感知子系统旨在探测任何直接的危险，并充当车辆安全的最后一道防线。它的探测范围覆盖车的近场，即车辆周围 0-5 米的范围。（在自动驾驶中，近场指的是车辆周围的相对较短距离。近场感知是自动驾驶系统中非常重要的一个功能，它能够帮助车辆在近场内精确检测周围的障碍物和人员，以便车辆能够安全行驶。），这是通过结合使用毫米波雷达和声呐来实现的。毫米波雷达是非常适合移动物体探测的工具，而声呐则适合静态物体探测。根据当前的车速，当检测到近场内的物体时，被动感知子系统会采取不同的策略来确保车辆的安全。

**1.3.2 模块化设计**

以往设计的自动驾驶计算系统的成本往往很高，但应用模块化设计的原则可以设计出经济实惠的计算解决方案[9]。模块化设计将计算推到了传感器端，从而减少了对主计算单元的计算需求。事实上，像DragonFly传感器模块[11]这样的四摄像头模块就能以400Mbps的速率产生图像数据。如果所有的传感器数据都被传输到主计算单元，那就要求这个计算单元变得极其复杂，这将对系统的可靠性、功率开支和成本等方面产生诸多不良后果。



我们采用的方法是将功能单元分解为若干模块，并让每个模块执行尽可能多的计算操作。这有助于减轻主计算系统的负担并简化其设计，从而提升系统可靠性。具体而言，我们在DragonFly模块中嵌入了GPU SoM（模块系统），以从原始图像中提取特征。然后，只将提取得到的特征发送给主计算单元，从而将数据传输速率降低了1000 倍。将相同的设计原则应用于 GNSS 接收器子系统和雷达子系统，可将整个计算系统的成本降低到 2000 美元以下。

**1.3.3 扩展现有的数字地图**

创建和维护高精度地图是自动驾驶车辆部署成本的另一个重要组成部分。一些人提议使用众包（crowd‐sourcing）数据创建高精度地图。但是，这需要车辆配备昂贵的激光雷达（LiDAR）装置，因此不适合大规模部署。而另一方面，许多汽车已经配备了摄像头，因此众包视觉数据是一种非常实用的解决方案。



所以，我们的理念是用视觉信息增强现有的数字地图，使其达到分米级的精度，而不是从头开始建立高精度地图。这被称为HPVMs（High-Precision Visual Maps）。为了有效地帮助车辆进行定位，HPVMs由多个层组成：

1. ` `最底层可以是任何现有的数字地图，例如Open Street Map；底层的分辨率约为1米。
1. 第二层是地面特征层。它记录了路面的视觉特征，以提高地图分辨率至分米级。在周围充满其他车辆和行人的拥挤的城市环境中，地面特征层特别有用。
1. 第三层是空间特征层，它记录了环境中的视觉特征；与地面特征层相比，它提供了更多的视觉特征，并且地图分辨率也达到了分米级。空间特征层在不太拥挤的开放环境（如乡村）中特别有用。
1. 第四层是语义层，包含车道标签、红绿灯和交通标志标签等。语义层可以帮助车辆做出规划决策，例如路线选择。

**1.4 模块化设计**

在我们讨论本书其他部分的细节之前，让我们简要回顾一下模块化设计方法，并介绍每个模块。通过这样的介绍，读者可以轻松了解本书的内容。

图1.2展示了DragonFly Pod[13]，这是一种利用本书所述的模块化设计方法构建的低速自动驾驶客舱。该车由多个部件组成，包括用于定位的实时差分定位（RTK） 全球导航卫星系统（GNSS）模块，用于定位和主动感知的DragonFly计算机视觉模块（使用视觉惯性里程计技术），用于被动感知的毫米波雷达和声呐，用于实施规划的规划与控制模块，和底盘模块。图1.3显示了该设计的架构图，并展示了各模块之间如何交互。

![图片](Aspose.Words.ca6e8170-2d72-4fa3-b069-82d5af9fff97.002.jpeg)

图1.2 DragonFly Pod的模块化设计

图1.2左侧从上到下依次为，DragonFly计算机视觉模块（DragonFly Computer Vision Modul），RTK GNSS模块（RTK GNSS Module），77GHz毫米波雷达（77 GHz mmWave Radar），声呐（Sonar），底盘（Chassis）；右侧是规划与控制模块（Planning and Control Module）。

![图片](Aspose.Words.ca6e8170-2d72-4fa3-b069-82d5af9fff97.003.jpeg)

图1.3 模块化设计架构

在图1.3中，最下方分别为底盘(Chassis)，声呐(Sonars)，雷达(Radar)；通过中间的控制器区域网络(CAN bus)将底层传感器与上面的规划与控制(Planning and Control)联系在一起，然后规划与控制和计算机视觉(Computer Vision)、地图(Map)以及全球定位系统(GNSS)关联在一起。

**1.4.1 通信系统**

首先，为了使不同的模块组成一个完整的工作系统，我们需要一个可靠的通信系统。由于控制器局域网络（CAN）总线简单易用，CAN总线被广泛运用于当今的车载通信网络，它可用于连接电子控制单元 (ECU)，传感器和其他组件，以实现彼此之间的通信。在进一步讨论其他组件的细节之前，读者应首先了解CAN总线的工作原理。

**1.4.2 底盘**

传统的汽车底盘利用机械控制，如机械电缆、液压和其他方式，为驾驶员提供对车辆速度或方向的直接的，物理上的控制方式。

然而，要实现自动驾驶，我们需要一个线控驱动底盘（drive‐by‐wire‐ready chassis），这样底盘就可以应用电子控制来启动刹车、控制转向和操作其他机械系统。具体而言，底盘模块为规划与控制模块提供基本的应用程序接口，使规划与控制模块能够进行转向、油门、刹车等动作，以保证车辆按规划的轨迹行驶。

**1.4.3 用于被动感知的毫米波雷达和声呐**

对于探测中距离范围内的障碍物，我们可以使用 77GHz 毫米波雷达，这样规划与控制模块就可以在探测到障碍物时立刻做出决策。同样，声呐可以用于近距离范围内的障碍物探测，为车辆安全提供最后一道防线；一旦声呐探测到障碍物，它们会直接向底盘发出停止信号，以最大限度地降低事故发生的风险。

毫米波雷达和声呐传感器可以结合使用，实现被动感知。所谓被动感知，即当探测到障碍物时，原始数据不会被送到规划与控制模块进行决策，而是通过 CAN 总线直接发送给底盘，以便快速做出决策。在这种情况下，车辆底盘上实现了一个简单的决策模块，以便在短距离内检测到障碍物时停止车辆。 

这种设计的主要原因是当近距离检测到障碍物时，我们希望尽快停止车辆，而不是通过完整的决策管道。这是保证乘客和行人安全的最佳方式。

**1.4.4 用于定位的GNSS**

当涉及到车辆定位时，我们很自然地就会选择GNSS系统，特别是具有RTK能力的GNSS系统，它可以提供非常高的定位精度。 GNSS 系统提供详细的定位信息，例如纬度、经度、海拔以及车辆航向。尽管如此，当有建筑物和树木遮挡住天空时，GNSS 精度会受到影响，从而导致多径问题。因此，我们不能完全依赖GNSS 进行定位。

**1.4.5 用于主动感知和定位的计算机视觉**

计算机视觉可用于定位和主动感知。为了实现准确的实时车辆定位，我们可以依靠视觉同步定位和地图绘制 (VSLAM) 技术。然而，VSLAM通常存在累积误差，随着车辆行驶的距离越来越长，定位误差就会变得越来越大。幸运的是，通过融合VSLAM和GNSS定位技术，我们可以在不同的情况下实现高精度定位，因为 GNSS 得到的数据在车辆未被遮挡时可以用作真值组（group‐truth），而 VSLAM 在 GNSS 被遮挡时可以提供高精度数据。

此外，计算机视觉也可用于主动感知。使用双目视觉，我们可以提取不同物体的空间或深度信息；使用深度学习技术，我们可以提取不同对象的语义信息。通过融合空间和语义信息，我们可以检测到感兴趣的物体，如行人和汽车，以及获得它们与当前车辆的距离。

**1.4.6 规划与控制**

规划与控制模块接收来自感知和定位模块的输入，并实时生成决策信息。通常，在不同的情况下，规划与控制模块会定义不同的行为，并选择其中一种行为执行。



一个典型的规划与控制系统具有以下架构：首先，当用户输入目的地时，路由模块会检查地图中的道路网络信息并生成路线。然后将路线传递给行为规划模块，该模块检查交通规则以生成运动规范。接下来，生成的路线连同运动规范被传递给运动规划器，运动规划器结合实时感知和定位信息来生成轨迹。最后，生成的轨迹被传递给控制系统，该系统会被动地纠正规划运动执行中的错误。

**1.4.7 建图**

地图生成模块向规划与控制模块提供必要的地理信息，例如车道配置和静态障碍物信息。为了生成实时运动规划，规划与控制模块可以将感知输入，定位输入，和地图输入相结合。感知输入可以实时检测动态障碍物，定位输入可以生成实时车辆姿态，地图输入可以捕获道路几何形状和静态障碍物。



目前，全自动驾驶车辆使用高精度3D地图。这种高精度地图极其复杂，包含数万亿字节的数据，这些数据不仅有表示车道和道路的，还有表示现实世界中三维地标的语义信息和位置的。有了高精度地图，自动驾驶车辆就能够在地图区域中定位自身位置和并实现导航功能，前往目的地。

**1.5  内容前瞻**

在前面的内容中，我们介绍了用于构建自动驾驶车辆或智能机器人的模块化设计方法。在本书的其余部分，我们将深入探讨这些主题，并详细介绍每个模块，以及如何集成这些模块以实现一辆功能齐全的自动驾驶车辆或智能机器人。

本书的第一部分由第2-8章组成，在这部分中我们介绍了自动驾驶车辆的各个模块，包括通信系统，底盘技术，被动感知技术，通过实时动态测量技术（RTK）全球导航卫星系统（GNSS）进行定位，用于定位与感知的计算机视觉，规划和控制，以及建图技术。

- 第2章：车载通信系统 
- 第3章：智能机器人和自动驾驶车辆的底盘技术
- 第4章：声呐和毫米波雷达的被动感知
- 第5章：通过实时动态全球导航卫星系统进行定位
- 第6章：计算机视觉的定位与感知
- 第7章：规划和控制
- 第8章：建图

本书的第二部分由第9章和第10章组成，在这部分中我们介绍了两个有趣的案例研究：第一个是关于应用模块化设计来建造低速的自动驾驶车辆；第二个是关于美国宇航局（NASA）如何使用模块化设计方法搭建其太空探索机器人。

- 第9章：搭建 DragonFly Pod 和 DragonFly Bus
- 第10章：搭建商业智能太空探索机器人

根据我们的实践经验，自动驾驶车辆和智能机器人的功能往往受到有限的车载计算能力的制约。因此，在本书的最后部分，我们深入研究了为自动驾驶车辆和智能机器人构建边缘计算系统的最先进方法。我们将涵盖车载边缘计算设计、车联网（Vehicle‐to‐Everything）基础设施以及自动驾驶车辆的安全性。

- 第11章：自动驾驶车辆的边缘计算
- 第12章：Vehicle‐to‐Everything基础设施的创新
- 第13章：车辆边缘系统安全

**1.6 书中使用的开源项目**

正如你所看到的，自动驾驶系统是一个高度复杂的系统，集成了很多技术部件和模块。因此，从头开始搭建自动驾驶车辆的一切是不可行且效率低下的。所以，我们在本书中引用了许多开源项目来帮助读者构建自己的自动驾驶系统。此外，在本书中，我们还使用了PerceptIn的自动驾驶软件堆栈来展示模块化设计的理念。本书中使用的开源项目列举如下：

- CANopenNode [14]：这是一个免费和开源的CANopen协议栈，用于CAN总线通信。
- Open Source Car Control [15]：开源车辆控制（Open Source Car Control）是软硬件设计的集合体，它能够对汽车进行计算机控制，以促进自动驾驶车辆技术的发展。它是一种使用软件与车辆的通信网络和控制系统对接的模块化的和稳定的方式。
- OpenCaret [16]：用于起亚Soul EV上的开源 Level-3 高速公路自动驾驶系统。
- NtripCaster [17]：NTRIP（通过互联网进行RTCM网络传输的协议）是在互联网上进行RTK数据传输的协议。GNSS NTRIP Caster从一个或多个数据流源（名为NTRIP服务器的基站）获取GNSS数据，并将这些数据提供给一个或多个终端用户（通常称为rover），即NTRIP客户端。如果你需要同时向一个以上的客户端发送数据，或有一个以上的数据流，你将需要一个Caster。
- GPSD [18]：这是一个服务守护进程，它监听一个或多个通过串行或USB端口连接到主机的GNSS接收器，使传感器的位置/路线/速度的所有数据可在主机的传输控制协议端口2947上查询。多个位置感知的客户端程序可以共享对支持GPSD的传感器的访问，而不会发生冲突或数据丢失。此外，GPSD响应查询的格式比大多数GNSS接收器发出的NMEA 0183格式更容易解析。
- Kalibr [19]：Kalibr是解决以下标定问题的工具箱：
  - 多摄像头标定：具有无重叠视场的相机系统的内外参标定。
  - 视觉-惯性标定（相机-IMU）：IMU相对于相机系统的空间和时间标定。
  - 卷帘快门相机标定：卷帘快门相机的全部内参标定（投影、失真和快门参数）。
- OpenCV [20]：OpenCV（Open Source Computer Vision Library）是一个开源的计算机视觉和机器学习软件库。OpenCV 旨在为计算机视觉应用程序提供通用基础架构，并加速机器感知在商业产品中的应用。
- ORB‐SLAM2 [21]：ORB‐SLAM2是支持单目（monocular）、双目（stereo）、RGB-D相机的实时SLAM库，用于计算相机轨迹和稀疏的三维重建（3D reconstruction）。它能够实时检测环路并重新定位摄像机。
- libELAS [22]：这是一个带有 MATLAB 包装器的跨平台的 C++ 库，用于计算大型图像的差异图（disparity maps）。它的输入是一对具有相同大小的整流灰度立体图像。输出是相应的差异图。
- Mask R‐CNN [23]：这是一个基于Keras和TensorFlow的用于目标检测和实例分割的深度学习模型。
- Baidu Apollo [24]：Apollo是一个具有高性能、灵活的架构，可以加速自动驾驶车辆的开发、测试和部署。
- OpenStreetMap [25]：是一个网上地图协作计划，旨在创造一个免费开源且能让所有人编辑的世界地图。地图背后的地理数据是该项目的主要产出。世界上大部分地区对地图数据的使用和提供都加以限制，这促使了OpenStreetMap计划的创立，而廉价的便携式卫星导航设备的出现进一步促进了OpenStreetMap计划的发展壮大。

**参考文献**

1. U.S. Department of Energy (2017). Emissions from Hybrid and Plug-In Electric Vehicles. <https://www.afdc.energy.gov/vehicles/electric_emissions.php> (accessed 1 December 2017).
1. MIT CSAIL (2016). Study: carpooling apps could reduce taxi traffic 75%. <https://www.csail.mit.edu/news/study-carpooling-apps-could-reduce-taxi-traffic-75> (accessed 1 December 2017).
1. VirginiaTech (2017). Automated vehicle crash rate comparison using naturalistic data. <https://www.vtti.vt.edu/featured/?p=422> (accessed 1 December 2017).
1. ` `U.S. Department of Transportation (2016). U.S. Driving Tops 3.1 Trillion Miles in 2015. <https://www.fhwa.dot.gov/pressroom/fhwa1607.cfm> (accessed 1 December 2017).
1. ` `Moore, F.C. and Diaz, D.B. (2015). Temperature impacts on economic growth warrant stringent mitigation policy. Nature Climate Change 5 (2): 127–131.
1. New York State Department of Transportation (2016). Average Accident Costs. <https://www.dot.ny.gov/divisions/operating/osss/highway-repository/39D1F023EC4400C6E0530A3DFC0700C6> (accessed 1 December 2017).
1. ` `Liu, S., Li, L., Tang, J. et al. (2017). Creating Autonomous Vehicle Systems, Synthesis Lectures on Computer Science, vol. 6, 1–186. Morgan & Claypool Publishers.
1. Liu, S., Tang, J., Wang, C. et al. (2017). A unified cloud platform for autonomous driving. Computer (12): 42–49.
1. Liu, S., Tang, J., Zhang, Z., and Gaudiot, J.-L. (2017). Computer architectures for autonomous driving. Computer 50 (8): 18–25.
1. AutonomousStuff (2017). Lincoln MKZ Platform. <https://autonomoustuff.com/product/lincoln-mkz> (accessed 1 October 2018).
1. YouTube (2018). PerceptIn DragonFly Sensor Module <https://www.youtube.com/watch?v=WQUGB-IqbgQ&feature=youtu.be> (accessed 1 October 2018).
1. Vega, P. (2018). UC Irvine grad works to make a self-driving car costing under $10,000. *Los Angeles Times*. <http://www.latimes.com/socal/daily-pilot/news/tn-dpt-me-driverless-cars-20180105-story.html> (accessed 8 January 2018).
1. PerceptIn (2017). PerceptIn DragonFly Pod. <https://www.perceptin.io/products> (accessed 1 October 2019).
1. GitHub (2019). CANopenNode. <https://github.com/CANopenNode/CANopenNode> (accessed 1 October 2019).
1. GitHub (2019). Open Source Car Control. <https://github.com/PolySync/oscc> (accessed 1 October 2019).
1. GitHub (2019). OpenCaret. October 2019, <https://github.com/frk2/opencaret> (accessed 1 October 2019).
1. ` `GitHub (2019). NtripCaster. <https://github.com/nunojpg/ntripcaster> (accessed 1 October 2019).
1. ` `gpsd (2019). gpsd – a GPS sevice daemon. <https://gpsd.gitlab.io/gpsd/index.html> (accessed 1 October 2019).
1. ` `GitHub (2019). Kalibr. <https://github.com/ethz-asl/kalibr> (accessed 1 October 2019).
1. ` `OpenCV (2019). OpenCV. [https://opencv.org](https://opencv.org/) (accessed 1 October 2019).
1. GitHub (2019). ORB-SLAM2. <https://github.com/raulmur/ORB_SLAM2> (accessed 1 October 2019).
1. Geiger, A. (2019). libELAS. <http://www.cvlibs.net/software/libelas> (accessed 1 October 2019).
1. GitHub (2019). Mask R-CNN. <https://github.com/matterport/Mask_RCNN> (accessed 1 October 2019).
1. GitHub (2019). Baidu Apollo. <https://github.com/ApolloAuto/apollo> (accessed 1 October 2019).
1. GitHub (2019). OpenStreetMap. <https://github.com/openstreetmap> (accessed 1 October 2019).


