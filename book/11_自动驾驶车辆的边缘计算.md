**11.自动驾驶车辆的边缘计算**

**11.1 简介**

正如第10章所指出的，由于需要实时对多个传感器的输入进行评估，机载传感器的自主性往往会受到计算系统性能的制约。这个问题不仅仅出现在火星上的空间探索机器人，同样也发生在地球上的自动驾驶车辆上。

例如，如果一辆自动驾驶汽车以每小时60英里的速度行驶，其制动距离大约是30米，这就要求自动驾驶系统在潜在危险发生前的几秒钟就能预测到它们。因此，自动驾驶车辆边缘计算系统的算力越强，那么计算这些复杂情况就越快，车辆自然也就越安全。 

简而言之，自动驾驶车辆边缘计算系统设计的目标是：在有限的能源预算内，保证用户安全的情况下，实时有效地处理大量的数据。

在接下来的几章中，我们将会介绍目前构建自动驾驶车辆边缘计算系统的先进方法。在本章中，我们将重点介绍车载计算系统；在第12章中，我们将介绍车用无线通信技术（Vehicle to Everything，V2X）如何减轻车载计算系统的压力；在第13章中，我们将介绍自动驾驶车辆边缘计算系统的安全问题。

在本章中，我们回顾了自动驾驶应用的边缘计算系统的最新设计过程。首先，我们在开头部分介绍了可用于评估边缘计算系统设计的基准套件。其次，我们回顾了应用于自动驾驶工作场景(workloads)下的计算系统架构的设计方法。接下来，描述了运行时层的设计，以有效地将传入的工作场景(workloads)映射到异构计算单元上。随后，我们介绍了自动驾驶不同功能模块所绑定的中间件的设计。最后，介绍了几种目前已经实现的自动驾驶边缘计算系统。

**11.2 基准（Benchmarks）**

为了提高计算系统的性能，往往会采用一个基准测试套件来评价目标应用程序在大部分工作场景(workloads)下的性能。同样的方法也适用于设计和改进自动驾驶车辆的边缘计算系统。

目前该领域的研究可以分为两类：数据集和工作场景(workloads)。KITTI是第一个与自动驾驶相关的基准数据集[1]。它由丰富的带标签的视觉数据组成，如单眼/立体图像数据和激光雷达（LiDAR）数据。它还提供了一种专门的方法，根据不同的数据类型，生成地面实况和计算评价指标。KITTI是为评估自动驾驶场景下的算法性能而建立的，包括但不限于视觉测距、车道检测、目标检测和目标跟踪。

除KITTI外，每个算法都有一些定制的基准数据集，例如用于RGB-D即时定位与地图构建(SLAM)算法的TUM RGB-D[2]，用于3D目标检测算法的PASCAL3D[3]，以及用于多目标跟踪算法的MOTChallenge[4]。这些数据集都有助于提高边缘计算系统的性能。

另一类的基准测试套件用于对新型硬件架构和软件框架的性能进行测试，他们通常由一组计算机视觉内核和应用程序组成。例如，圣地亚哥视觉基准套件（SD- VBS）[5]和MEVBench[6]都是用于移动计算机视觉系统的性能测试基准套件。SD‐VBS提供了运用C和MATLAB实现了9个高级视觉应用的单线程。MEVBench是基于SD‐VBS的扩展程序，它提供了15个视觉应用的单线程和多线程的C++实现方式。然而，这两个基准的创建早于自动驾驶领域，因此它们不适用于图形处理单元(GPUS)等异构平台，也不包含深度学习算法等新颖的工作负载。

SLAMBench[7]使用一个完整的RGB-D SLAM应用程序来评估新的异构硬件。它的实现基于KinectFusion[8]，并且为异构硬件提供了C++, OpenMP, OpenCL 和 CUDA版本的关键核函数。这些基准对于自动驾驶的边缘计算系统有一定的作用，但是还远远不够。我们需要的是一个包含了自动驾驶车辆各种应用场景下不同场景的全面基准(例如用于微型飞行器系统测试的MAVBench[9]，自动驾驶系统也需要一个类似的基准来评价各项工作的性能。

CAVBench是目前最新发布的一个基准测试套件，主要用于评估无人驾驶汽车(CAVs)计算系统的性能[10]。它总结了CAVs的四个应用场景（自动驾驶、实时诊断、车载信息娱乐和第三方应用），并选择了六个经典的、多样化的车载应用作为评估的工作场景(workloads)（SLAM、目标检测、目标跟踪、电池诊断、语音识别和边缘影像分析）。

CAVBench将四个应用场景的数据集输入到6种工作场景(workloads)下，然后输出两个评价指标。第一个是对应用程序的评价指标，其中包含每个应用程序的执行时间明细，以帮助开发人员找到程序方面的性能瓶颈。另一个是对系统的评价指标，称为服务资源利用质量曲线(QoS‐RU curve)，可以看作是计算平台的性能量化指标，帮助研究人员和开发人员优化车载应用和CAVs计算架构。CAVBench的发布是为自动驾驶边缘计算系统的发展提供了一个良好的开端，希望未来能够研发出更多自动驾驶领域的基准测试套件。

自动驾驶是一个快速发展的领域，我们希望能够采集尽可能多的数据来涵盖复杂的自动驾驶应用场景。此外，目前还缺少标准化的评分方法，以根据不同的优化指标对不同的边缘计算系统进行排名。

**11.3  计算系统架构**

一旦有了标准的基准套件，我们就可以开始针对自动驾驶的工作场景(workloads)开发合适的计算系统架构。Liu等人提出了一个利用混合异构硬件设计的自动驾驶计算系统架构[11]。 该架构将自动驾驶的应用分为三个阶段：感知、预测和决策。作者通过比较不同的硬件在完成自动驾驶任务时的性能，得出了以下结论：定位和感知模块是自主驾驶计算系统的瓶颈。并且，他们还确定了不同工作负载下所需求的硬件加速器。此外，作者提出并开发了一种模块化、安全、动态、高性能、节能的计算系统架构，此架构中充分利用了中央处理器（CPU）、图形处理单元（GPU）和数字信号处理器（DSP）等异构计算组件。实验显示，在每小时5英里的车速下，其系统在ARM移动芯片系统（SoC）上平均功耗为11瓦。作者表示，如果能有足够的计算资源，该系统将能处理更多的数据，并最终满足量产级自动驾驶系统的需求。

Lin等人在[12]中探索了自动驾驶系统架构的性能限制与提升方式。作者提出并详细阐述了自动驾驶系统在性能、可预测性、存储、热能和功率方面的设计约束。基于这些设计约束，作者开发了一种基于机器学习算法的端到端自动驾驶系统，通过对该系统的实验，作者确定了计算系统的三个瓶颈：定位、物体检测和物体跟踪。为了设计一个能够满足所有设计约束的系统，作者用三种不同的加速器平台来加速这三个计算瓶颈。实验证明，GPU、现场可编程门阵列（FPGA ）和ASIC加速系统能有效地减少了这些算法的尾部延时。尽管像GPU这样的加速平台可以有效地降低计算的延迟，但它们的功耗往往较高，需要更强的散热系统，系统整体的工作负荷增大，导致车辆的行驶里程和燃油效率下降。最后，作者指出，计算能力是阻碍获得更精确感知信息的瓶颈，从而影响了系统的精度。因此，平衡好自主驾驶系统的性能、功率和可扩展性之间的关系，是系统设计的关键。

有趣的是，上述作者经过架构设计的开创性探索后，都认为算力的瓶颈在定位和感知，并指出异构计算是目前可行的加速方式。对于定位的加速，Tang等人提出了一个用于SLAM的异构架构[13]。作者首先进行了深入研究了现有异构SoC上视觉惯性SLAM的性能和能耗。研究结果表明，现有的SoC没有针对SLAM应用进行优化，在IO接口、内存子系统以及计算加速方面存在优化的空间。基于这些，作者提出了一种针对视觉惯性SLAM应用优化的异构SoC架构。该架构并不是简单地添加一个加速器，而是系统地集成了直接IO、特征缓冲区和特征提取加速器。作者在Xilinx Zynq UltraScale MPSoC上运用该架构进行测试，数据显示，此架构能以低于5W的平均功率提供超过60帧/秒（FPS）的性能。实验结果证明了所提出的架构能够实现视觉惯性 SLAM应用的性能和能耗优化。

Zhang等人也提出了一种解决定位算力问题的方法——视觉惯性里程表（VIO）系统的算法和硬件协同设计[14]。该方法中，机器人通过机载摄像头和惯性测量单元（IMU）（以及基于地标的地图）数据估计其自我运动。作者认为，在不牺牲性能的前提下将VIO运用到小型平台中需要改变感知算法的设计模式，对此，作者提倡使用算法和硬件设计紧密耦合的协同设计方法。作者展开讨论了一组相关的设计选择如何影响VIO中的资源与性能的平衡。此外，为了证明协同设计方法的有效性，作者在专用硬件上实现了VIO。实验数据显示，在保证精度和速度相同的情况下，所需的功耗明显小于桌面端。

除了学术研究外，PerceptIn 最近还发布了一个名为DragonFly+的商业化SLAM系统[15]。DragonFly+是一个基于FPGA的实时定位模块，具有以下几个优势：(i) 四个图像通道以及IMU之间的硬件同步；(ii) 直接的IO架构，减少片外内存通信；(iii)以及一个完全的流水线架构来加速图像的前端处理。此外，还采用了并行和多路复用处理技术，以实现带宽和硬件资源消耗之间的良好平衡。数据显示，DragonFly+在处理四路720p图像时，能够达到42FPS的性能，而功耗仅为2.3W。相比之下，Nvidia Jetson 175 TX1 GPU SoC在7W的功耗下达到了9 FPS的性能, Intel Core i7在80W的功耗下达到了15 FPS的性能。可以发现，与Nvidia TX1相比，DragonFly+的功耗效率提高了2倍，计算能力提高了4倍；与Intel Core i7相比，功耗效率提高了33倍，计算能力提高了2倍。

在感知方面，目前的研究大多集中在深度卷积神经网络（CNNs）的加速上。为了提升CNN加速的效率和灵活性，以使其支持各种不同的应用，Liu等人提出了一种用于神经网络加速的新型特定领域指令集架构（ISA）[16]。该ISA是一个在综合分析了现有神经网络加速技术的基础上，集成了标量、矢量、矩阵、逻辑、数据传输和控制指令的负载存储架构。实验结果表明，作者所提出的ISA在广泛的神经网络加速技术上具有很强的描述能力，并提供了比通用ISA(如x86、MIPS和GPGPU)更高的代码密度。

Chen等人意识到数据移动是CNN计算瓶颈的关键，因此提出了一种数据流，以最小化空间架构上数据移动的能耗[17]。该方法实现的关键是在高维卷积中重复使用过滤器权重和特征图像素的局部数据，或是运用激活函数，并最小化部分累加和的数据移动。因此该数据流能够适应不同的CNN形状配置，通过最大限度地利用处理引擎(PE)的本地存储、空间并行性和PE间直接通信来减少所有类型的数据移动。为了验证该数据流的有效性，作者将该数据流配置到AlexNet 的 CNN 中。实验表明，对于卷积层和完全连通层，该数据流比其他数据流具有更高的能量效率。

在不久的将来，随着自动驾驶使用场景以及相关工作场景(workloads)的增加，我们希望看到更多针对这些工作场景(workloads)的加速方案。同时，我们也期望看到更多在缓存、内存和存储架构上的探索性研究。此外，自主驾驶的硬件安全性也同样至关重要。预计在十年内，学术界和工业界能够针对自动驾驶的工作场景(workloads)提出一种“通用”的架构设计。

**11.4 运行时层（Runtime）**

有了自动驾驶的计算系统架构之后，接下来需要考虑的是如何设计运行时层，才能高效地分配任务，以实现最佳的性能和资源利用率。自动驾驶系统运行时层是一个具有巨大潜力的全新研究领域，目前的运行时层大多侧重于将一种算法映射到一种类型的加速器上，或是侧重于用一个加速器对同类或异构系统进行调度。

一些现有的设计方案专注于将深度学习或计算机视觉的工作负载(workloads)映射到异构架构上。例如，Hegde等人提出了一个框架[18]，可以轻松地将 CNN 规范应用到诸如 FPGA、 DSP、图形处理器和多核精简指令集计算机(RISC)之类的加速器上。Malik等人则比较了计算机视觉算法在FPGA和GPU加速器上的性能和能效[19]。

目前有许多研究探索了如何在GPU或FPGA等嵌入式平台上优化深度学习[20,21]或计算机视觉算法。例如，Honegger等人提出了基于FPGA的嵌入式计算机视觉加速技术[22]。Satria 等人在基于 GPU 的嵌入式平台上进行了人脸检测的优化，并提供了性能报告[23]。Vasilyev 等人评估了可编程结构上的计算机视觉算法[24]。Nardi等人提出了一套基准套件，从精度、性能和能耗方面评估了桌面和嵌入式平台上的密集SLAM算法[25]。然而，这些设计只是侧重于将一个算法应用到不同的加速器上，并没有考虑如何将各种工作任务(workloads)集成到一个系统中。

目前，在单ISA多处理器架构中，通常会使用一个加速器来完成调度，受此启发，许多设计方案使用一个加速器来完成异构系统架构的调度，如大小核的非对称多核体系结构，以及CPU + GPU的多ISA多处理器架构。在单 ISA 多处理器中，为了在运行时将工作分配到最合适的内核类型上，人们在操作系统层面做了许多的工作。Koufaty等人指出，内核停滞期是预测最匹配的内核类型的一个合适指标[26]。基于该指标，在操作系统中加入偏置调度策略，能够提高系统的吞吐量。Saez等人在[27]中提出了一种调度器，它在操作系统中添加了性能特化和 TLP (线程级并行性)特化，以便同时优化吞吐量和系统功耗。

性能特化（Efficient specialization）将CPU密集型的工作分配给高速内核，将内存密集型的工作分配给低速内核。TLP特化在程序的串行阶段使用高速内核，在并行阶段使用低速内核，以此来提高能源效率。在非对称多核架构方面，Jiménez等人在[28]提出了一种类似GPU系统的CPU用户级调度器，它在初始阶段评估并记录应用程序在每个PE上的性能，然后根据这些信息将应用程序分配给最合适的PE。Luk等人专注于改善单个进程的延迟和能量消耗[29],通过动态编译来提升性能，以确定最佳的任务分配，并为 CPU 和 GPU 生成代码。

Liu 等人最近提出了一个与现有的运行层不同的设计方案——PIRT (PerceptIn Runtime) ，这是第一个能够动态地将各种计算机视觉和深度学习工作负载(workloads)映射到多个加速器和云平台的运行时层架构[30]。作者首先对异构 SoC 架构上新兴的机器人应用进行了全面研究。并基于研究结果，作者设计出了PIRT。此方案不仅利用了片上异构计算资源，还利用了云技术，以实现高性能和高能效。为了验证方案的有效性，作者将PIRT部署在一个生产型移动机器人上，测试了机器人所有的工作场景，主要包括自主导航、障碍物检测、路径规划、全局地图生成和场景理解等。实验结果显示，上述所有的工作任务能够在11W的功耗下同时并且高效执行。

运行时层连接了自动驾驶的软件和硬件，在未来，自动驾驶运行时层的设计将变得更加困难。首先，随着计算系统的异构性越来越强，为了动态地分配传入的工作任务，运行时层的设计将变得更加复杂。其次，随着更多边缘云的出现，运行时层需要具备云感知能力，并能够将工作任务分发到边缘云。第三，运行时层应提供良好的抽象（abstraction）来隐藏所有的底层次实现。

**11.5 中间件**

机器人系统之中多个模块之间往往存在各种依赖关系，自动驾驶系统也是如此。中间件简化了软件设计，解决了系统中不同传感器之间底层通信的问题，实现各个系统模块之间的交互。

Miro应用于早期的机器人中间件，是一个基于公共对象请求代理架构 (COBRA)技术的面向移动机器人控制的分布式框架[31]。Miro的核心组件开发基于一个面向对象的多平台框架——ACE自适配通信环境（Adaptive  Communications Environment），该框架实现了操作系统以外的进程间通信、网络通信和实时通信 。Miro 提供了诸如本地化或行为引擎之类的通用抽象服务，支持Pioneers、 B21、机器人足球和各种机器人传感器等不同的机器人平台。

Orca 是一个开源软件框架，用于开发基于组件的机器人系统，它提供了许多可用于构建移动机器人系统的免费的可复用组件[32]。以下是ORCA框架开发的目的：通过定义一组常用接口来实现软件的复用；通过为库提供方便的应用程序接口来简化软件复用；通过维护组件库来鼓励软件的复用。

Urbi 是一个开源的跨平台软件，主要用于开发机器人和复杂系统的应用程序[33]。Urbi 基于 UObject 分布式 C + + 组件架构，其中包含了一种并行和事件驱动脚本语言——urbiscript。UObject 组件可以作为本机对象插入到 urbiscript 中，以指定它们的交互和数据交换。UObjects 可以链接到 urbiscript 解释器，或者在另一个线程、另一个进程、本地网络上的另一台机器或是远程网络上的另一台机器中，以“远程”模式作为自主进程执行。

Runtime(RT)中间件是基于分布式对象技术的机器人平台通用标准[34]。RT中间件可以通过集成各种具有网络功能的机器人组件（RT-组件）来支持各种网络机器人系统的构建。在RT中间件中，执行器等机器人组件被视为RT组件，整个机器人系统由这些RT组件连接组成。这种分布式架构有助于开发人员复用机器人组件，并提高机器人系统的可靠性。

OpenRDK 是一个用于开发松散耦合模块的机器人开源软件框架[35]。它实现了透明的并发管理，通过套接字管理进程间的通信，通过共享内存管理进程内的通信，并且还提供了连接到模拟器和通用机器人驱动程序的模块。

上述中间件大多作为移动机器人的软件管理框架，并没有被应用于自动驾驶车辆。除了上述中间件之外，机器人操作系统（ROS）由于开发人员的普及型和软件库的丰富性，被广泛应用于自动驾驶车辆的开发中[36]。然而，如11.2节所述，ROS在性能、可靠性和安全性方面存在不足，因此但它并不适合作为产品化的自动驾驶解决方案。

中间件实现了自动驾驶系统中不同模块的通信。中间件应当该符合以下几点要求：

第一，中间件应当将计算开销和内存占用降到最低，具备可扩展性。

第二，由于一些自动驾驶任务可能停留在边缘云中，因此中间件需要能够实现客户端和云平台之间的通信。

第三，也是最重要的一点，中间件应当是安全可靠的，以保证服务质量和自动驾驶车辆的安全。




|` `**层级**              |` `**作用**                                                |` `**解决方案**  |` `**研究方向**                                                     |
| :-: | :-: | :-: | :-: |
|` `架构              |` `硬件层—执行自动驾驶工作负载的硬件计算单元           |` `[11]–[17] |` `自动驾驶工作负载的加速器;Cache和存储器结构设计;关键数据的非易失存储;硬件安全 |
|` `运行时层(Runtime) |` `软件层—在程序运行时将传入的任务分派给不同的计算单元 |` `[18]–[30] |` `高度异构计算系统的调度器和调度器;抽象化;云感知               |
|` `中间件            |` `软件层—实现自动驾驶各服务之间的复杂交互             |` `[31]–[36] |` `低开销和低内存占用;边云协同;安全性和可靠性                   |
|` `基准              |` `评估边缘计算系统的工具                              |` `[1]–[10]  |` `更多的动态工作负载和数据，以覆盖更多的使用场景;对边缘计算系统进行排名的标准化的评分方法 |

**11.6 案例研究**

为了在嵌入式系统上，同时实现定位、感知和语音识别等多种自动驾驶服务，Tang等人设计了并实现了一个完整的自动机器人和车辆边缘计算框架π‐Edge[37]。设计这样一个系统需要考虑以下问题：如何以最小的开销管理不同的自动驾驶服务及其通信，如何充分利用边缘设备上的异构计算资源，并将一些任务卸载到云端以提高能源效率。基于上述问题，作者首先开发了一个运行时层，以充分利用低功耗边缘计算系统的异构计算资源；随后，开发了一个极其轻量级的中间件来管理多个自动驾驶服务及其通信；最后，开发了一个边缘-云协调器，将任务动态卸载到云端，以优化客户端系统能耗。

另外还有一个名为OpenVDAP的全栈边缘计算系统，其中包括了一个车辆计算单元，一个具备隔离性、安全性和隐私保护性的车辆操作系统，一个边缘感知的应用库，以及任务卸载和调度策略[38]。OpenVDAP允许CAVs动态地检查每个任务的状态，计算最低开销和最优的调度方法，从而使每个服务可以在低开销的情况下近乎实时地完成。此外，OpenVDAP还提供了一个免费、开放的边缘感知库，其中包含了基于边缘计算的车辆应用程序的部署方式和访问接口，以及各种常用的人工智能模型，从而使研究人员和开发人员能够在实际环境中部署、测试和验证其应用程序。



**参考文献**

**1** Geiger, A., Lenz, P., and Urtasun, R. (2012). Are we ready for autonomous driving? The KITTI vision benchmark suite. In: *2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 3354–3361. IEEE. 

**2** Sturm, J., Engelhard, N., Endres, F. et al. (2012). A benchmark for the evaluation of RGB‐D SLAM systems. In: *2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)*, 573–580. IEEE. 

**3** Xiang, Y., Mottaghi, R., and Savarese, S. (2014). Beyond PASCAL: a benchmark for 3D object detection in the wild. In: *2014 IEEE Winter Conference on Applications of Computer Vision (WACV)*, 75–82. IEEE. 

**4** Leal‐Taixé, L., Milan, A, Reid, I. et al. (2015). MOTChallenge 2015: Towards a benchmark for multi‐target tracking. arXiv preprint arXiv:1504.01942.

**5** Venkata, S.K., Ahn, I., Jeon, D. et al. (2009). SD‐VBS: the San Diego vision benchmark 

suite. In: *2009 IEEE International Symposium on Workload Characterization (IISWC)*, 55–64. IEEE.

**6** Clemons, J., Zhu, H., Savarese, S., and Austin, T. (2011). MEVBench: a mobile computer vision benchmarking suite. In: *2011 IEEE International Symposium on Workload* *Characterization (IISWC)*, 91–102. IEEE.

**7** Nardi, L., Bodin, B., Zeeshan Zia, M. et al. (2015). Introducing SLAMBench, a performance and accuracy benchmarking methodology for SLAM. In: *2015 IEEE International* *Conference on Robotics and Automation (ICRA)*, 5783–5790. IEEE.

**8**  Newcombe, R.A., Izadi, S., Hilliges, O. et al. (2011). KinectFusion: real‐time dense surface mapping and tracking. In: *2011 10th IEEE International Symposium on Mixed and* *Augmented Reality (ISMAR)*, 127–136. IEEE.

**9** Boroujerdian, B., Genc, H., Krishnan, S. et al. (2018). MAVBench: micro aerial vehicle benchmarking. In: *2018 51st Annual IEEE/ACM International Symposium on* *Microarchitecture (MICRO)*, 894–907. IEEE.

**10** Wang, Y., Liu, S., Xiaopei, W., and Shi, W. (2018). CAVBench: a benchmark suite for connected and autonomous vehicles. In: *2018 IEEE/ACM Symposium on Edge Computing* *(SEC)*, 30–42. IEEE.

**11** Liu, S., Tang, J., Zhang, Z., and Gaudiot, J.‐L. (2017). Computer architectures for autonomous driving. *Computer* 50 (8): 18–25.

**12** Lin, S.‐C., Zhang, Y., Hsu, C.‐H. et al. (2018). The architectural implications of autonomous driving: constraints and acceleration. In: *Proceedings of the Twenty‐Third* *International Conference on Architectural Support for Programming Languages and* *Operating Systems*, 751–766. ACM.

**13** Tang, J., Yu, B., Liu, S. et al. (2018). π‐SoC: heterogeneous SoC architecture for visual inertial SLAM applications. In: *2018 IEEE/RSJ International Conference on Intelligent* *Robots and Systems (IROS)*, 1–6. IEEE.

**14** Zhang, Z., Suleiman, A.A.Z., Carlone, L. et al. (2017). Visual‐inertial odometry on chip: An algorithm‐and‐hardware co‐design approach. Robotics: Science and Systems, Cambridge, MA.

**15** Fang, W., Zhang, Y., Bo, Y., and Liu, S. (2018). DragonFly+: FPGA‐based quad‐camera visual SLAM system for autonomous vehicles. In: *2018 IEEE HotChips*, 1. IEEE.

**16** Liu, S., Zidong, D., Tao, J. et al. (2016). Cambricon: an instruction set architecture for neural networks. In: *ACM SIGARCH Computer Architecture News*, vol. 44, 393–405. IEEE Press.

**17** Chen, Y.‐H., Emer, J., and Sze, V. (2016). Eyeriss: a spatial architecture for energy‐efficient dataflow for convolutional neural networks. In: *ACM SIGARCH Computer Architecture* *News*, vol. 44, 367–379. IEEE Press.

**18** Hegde, G., Ramasamy, N., Kapre, N. et al. (2016). CaffePresso: an optimized library for deep learning on embedded accelerator‐based platforms. In: *Proceedings of the* *International Conference on Compilers, Architectures and Synthesis for Embedded Systems* *(CASES)*, 14. ACM.

**19** Malik, M., Farahmand, F., Otto, P. et al. (2016). Architecture exploration for energy‐efficient embedded vision applications: from general purpose processor to domain specific accelerator. In: *2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)*, 559–564. IEEE.

**20** Cavigelli, L., Magno, M., and Benini, L. (2015). Accelerating real‐time embedded scene labeling with convolutional networks. In: *2015 52nd ACM/EDAC/IEEE Design Automation* *Conference*, 108. ACM.

**21** Qiu, J., Wang, J., Yao, S. et al. (2016). Going deeper with embedded FPGA platform for convolutional neural network. In: *ACM International Symposium on FPGA*, 26–35. ACM.

**22** Honegger, D., Oleynikova, H., and Pollefeys, M. (2014). Real‐time and low latency embedded computer vision hardware based on a combination of FPGA and mobile CPU. In: *2014 IEEE/RSJ International Conference on Intelligent Robots and Systems*, 4930–4935. IEEE

**23** Satria, M.T., Gurumani, S.T., Zheng, W. et al. (2016). Real‐time system‐level implementation of a telepresence robot using an embedded GPU platform. In: *2016 Design,* *Automation & Test in Europe Conference & Exhibition (DATE)*, 1445–1448. IEEE.

**24** Vasilyev, A., Bhagdikar, N., Pedram, A. et al. (2016). Evaluating programmable architectures for imaging and vision applications. In: *2016 49th Annual IEEE/ACM* *International Sysmposium on Microarchitecture (MICRO)*, 38–49. ACM.

**25** Nardi, L., Bodin, B., Zia, M.Z. et al. (2015). Introducing SLAMBench, a performance and accuracy benchmarking methodology for SLAM. In: *IEEE International Conference on* *Robotics and Automation (ICRA)*, 5783–5790. IEEE.

**26** Koufaty, D., Reddy, D., and Hahn, S. (2010). Bias scheduling in heterogeneous multi‐core architectures. In: *Proceedings of the 5th European Conference on Computer Systems*, 125–138. ACM.

**27** Saez, J.C., Prieto, M., Fedorova, A., and Blagodurov, S. (2010). A comprehensive scheduler for asymmetric multicore systems. In: *Proceedings of the 5th European Conference on* *Computer Systems*, 139–152. ACM.

**28** Jiménez, V.J., Vilanova, L., Gelado, I. et al. (2009). Predictive runtime code scheduling for heterogeneous architectures. In: *High Performance Embedded Architectures and Compilers.* *HiPEAC 2009*, 19–33. Springer.

**29** Luk, C.‐K., Hong, S., and Kim, H. (2009). Qilin: exploiting parallelism on heterogeneous multiprocessors with adaptive mapping. In: *Proceedings of the 42nd Annual IEEE/ACM* *International Symposium on Microarchitecture*, 45–55. ACM.

**30** Liu, L., Liu, S, Zhang, Z. et al. (2018). PIRT: A runtime framework to enable energy‐efficient real‐time robotic applications on heterogeneous architectures. arXiv preprint arXiv:1802.08359.

**31** Utz, H., Sablatnog, S., Enderle, S., and Kraetzschmar, G. (2002). Miro‐middleware for mobile robot applications. *IEEE Transactions on Robotics and Automation* 18 (4): 493–497.

**32** Brooks, A., Kaupp, T., Makarenko, A. et al. (2005). Towards component‐based robotics. In: *2005 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)*, 163–168. IEEE.

**33** Baillie, J.‐C. (2005). URBI: towards a universal robotic low‐level programming language. In: *2005 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)*, 820–825. IEEE.

**34** Ando, N., Suehiro, T., Kitagaki, K. et al. (2005). RT‐middleware: distributed component middleware for RT (robot technology). In: *2005 IEEE/RSJ International Conference on* *Intelligent Robots and Systems (IROS)*, 3933–3938. IEEE.

**35** Calisi, D., Censi, A., Iocchi, L., and Nardi, D. (2008). Open‐ RDK: a modular framework for robotic software development. In: *2008 IEEE/RSJ International Conference on Intelligent* *Robots and Systems (IROS)*, 1872–1877. IEEE.

**36** Quigley, M., Conley, K., Gerkey, B. et al. (2009). ROS: an open‐source robot operating system. In: *ICRA Workshop on Open Source Software*, vol. 3, 5. IEEE.

**37** Tang, J., Liu, S., Yu, B., and Shi, W. (2018). Pi‐edge: A low‐power edge computing system for real‐time autonomous driving services. arXiv preprint arXiv:1901.04978.

**38** Zhang, Q., Wang, Y., Zhang, X. et al. (2018). OpenVDAP: an open vehicular data analytics platform for CAVs. In: *2018 IEEE 38th International Conference on Distributed Computing* *Systems (ICDCS)*, 1310–1320. IEEE.


