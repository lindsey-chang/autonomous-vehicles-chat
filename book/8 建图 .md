**8 建图** 

**8.1 简介**

如图8.1所示，地图模块为控制和规划模块提供基本的环境信息，例如所处位置的车道排布和在当前位置下静态障碍物等信息。控制和规划模块会结合输入的感知信息（实时检测移动障碍目标）、定位信息（实时生成汽车位置信息）和地图（检测道路形状和静态障碍目标）来生成实时移动规划。

![图片](Aspose.Words.ab5bfc80-fed2-46a5-a0f5-8079ab04e10d.001.jpeg)

图 8.1模块化设计架（Chassis:汽车底盘 Sonars:声呐 Radars:毫米波雷达 CAN Bus:CAN总线 Plannning and Control:控制和规划模块 Map:地图 Computer Vision:计算机视觉 GNSS:全球定位系统）

因此，必须要通过高精度的地图信息来帮助自动驾驶汽车实现自动驾驶功能。具体来说，规划和控制模块必须将汽车的实时位置（从定位模块获得的结果）映射到地图上以得出汽车目前是在哪条车道上行驶。此外，规划和控制模块还会将检测到的移动障碍物（从感知模块获得的结果）映射到地图上并依此决定车辆的下一步的运动规划决策（如继续前进、停止或者改变行驶车道等）。所以，如果自动驾驶汽车所使用的地图不够准确或者精度达不到要求，在车辆处于自动驾驶状态期间，车辆很容易发生事故。目前，主流的全自动驾驶汽车（如Waymo和Uber的自动驾驶汽车）都是使用的高精地图。这种地图非常复杂，其包含了数万亿字节的数据，在这些地图的数据中，不仅包含了车标和道路信息，还包含了语义信息和现实世界中的三维地标位置[1]。高精地图能够使得自动驾驶汽车在地图表示区域内实现定位与导航的功能。

在这一章节，我们将深入研究建图技术， 首先会仔细了解传统数字地图、高精地图，并在现有的数字地图的基础上进行一些拓展（本文讲述如何构建一个π-Map）以实现简单的自动驾驶来加深对这些地图的理解。

**8.2 数字地图**

如谷歌地图、必应地图和开源地图（Open Street Map，OSM）之类的数字地图是以人类而不是以机器为受众去开发的，因此这类数字地图极其依赖人的认知和观察。例如，谷歌地图只会实时告诉你当前在哪条街/路，但不会告诉你在这条街/路的哪一个车道上，因此使用者必须根据其认知（比如交通规则）结合其目前观测到的结果（比如目前的交通状况）来做出下一步决定。在本小节，我们以开源地图（OSM）为例来，详细介绍了数字地图的细节。而在8.3节中，我们将介绍高精地图的细节。

**8.2.1 OSM开源地图**

开源地图是一个免费的、可编辑的世界地图，该地图主要由志愿者们一点一点的建立起来并且其遵循内容开源协议（开源地图的网址：[www.openstreetmap.org](https://www.openstreetmap.org)）。开源地图由第三方供应商提供的原始地理数据和一套用于创建和分享地图信息的软件工具构成。

**1.OSM数据结构**

首先，让我们查看一下OSM图的数据结构组成。开源地图数据由以下基本元素组成。

- 节点（Node）：节点是一个用于在地图上标记位置的圆点。节点与节点之间既可以是相互独立的，也可以是相互连接的。
- 路（Way）：路是节点之间的连线，其用于创建道路、路径、河流等标识。
- 闭合路（Closed way）：闭合路是构成了闭环的路，闭合路内部会构成区域。
- 区域（Area）：区域是闭合路所围城内部区域，一般区域会伴随着闭合路出现。
- 关系（Relation）：关系可以被用于创建更加复杂的地域形状。也可以用于表示一些没有空间关系的相关元素。这里我们不会深入讨论该元素组

我们可以使用标签来对这些基本元素进行注解以赋予这些元素基本的语义信息。标签可以通过<key, value>键值对来对元素进行描述。例如，如果我们需要在地图上构建一个餐馆，我们只需要创建一个节点，并在中添加如下标签来实现：shop = restaurant. name = John's Mexican Food。

需要注意的是，许多像building、amenity之类的键（Key）会使得OSM自动将周边的路转变为一个闭合路。因为闭合路元素会默认存在一个区域，所以我们一般很少会在闭合路中直接创建一个区域。（在闭合路元素中通过一个area = yes标签来创建一个区域）

下面是几个比较重要的Key标签

- Key:highway—用于标记公路、道路、路径、人行道、自行车、公共汽车站等。
- Key:place—用于标记国家、城市、城镇、村庄等。
- Key:amenity—用于标记一些有用的设施，如餐馆、饮水点、停车场等
- Key:shop—用于标记购买产品的商店
- Key:building—用于标注建筑物
- Key:landuse—用于标记人为土地
- Key:natural—用于标记自然土地，例如森林

**2.OSM软件栈**

OSM提供了一套软件工具用于导入、导出、存储、修改、渲染和可视化地图数据。OSM的架构如图8.2所示，它们被分为了如下五个部分。

![图片](Aspose.Words.ab5bfc80-fed2-46a5-a0f5-8079ab04e10d.002.jpeg)

图8.2 OSM架构图（WMS Service：网络地图服务 bing imagery：必应地图 GPX traces,photos and notes：含有GPX信息的轨迹，图片和记录 Map editing software：地图编辑软件 Geodata：地理数据 Import scripts：导入脚本 API：应用程序编程接口 OpenStreetMap Database(PostgreSQL)：开源地图数据库（PostgreSQL） Front Page Map Layers：前端页面地图层 Web Maps：网络地图 Other web map libraries：其他网络地图库 Vector plugins：矢量插件 Map apps：地图app Mobile SDKs：移动端SDKs osm-carto Style-sheet：osm-carto 样式表 mod\_tile cache：mod\_tile 缓存 Transport Renderer：传输渲染器 HOT Renderer：HOT 渲染器 Other Raster tiles：其他的栅格瓦片 Rendering databases：渲染数据库 Vector tiles：矢量瓦片 Editing：编辑工具 Backend：后端工具 Rendering：渲染工具 Visualization：可视化工具）

- 地理数据（Geodata）：该部分与地理信息位置有关，其以一种可以与地理信息系统（geographic information system，GIS）相兼容的存储格式进行存储。地理数据可以存储在数据库、地理数据库、Shapefile文件、Coverage文件、光栅图像、甚至是dbf表中。其中，网络地图服务（Web Map Service，WMS）是由开放地理空间信息联盟（Open Geospatial Consortium）在1999年发布的标准协议，主要用于为互联网地图提供地理参考的地图图像。
- 编辑工具（Editing）：我们可以使用例如ID、Java OpenStreetMap Editor（JOSM）和Vespucci的编辑软件来对OSM进行编辑，我们将会在8.2.2小结中详细介绍JOSM。
- 后端工具（Backend）：OSM的后端由一组工具组成，其主要用于存储和检索地理数据。例如，你可以在PostgreSQL中存储地理数据，并使用Nominatim来搜索数据库。我们会在8.2.3小结中详细介绍Nominatim。
- 渲染工具（Rendering）：OSM提供了一套渲染工具，将原始地理数据渲染成二维或三维图像。
- 可视化工具（Visualization）：OSM提供了一系列用于可视化地图的工具，而其中最受欢迎的就是OSM网站，用户可以在网址中方便的查看地图。

**8.2.2 Java OpenStreetMap编辑器**

JOSM用户界面如图8.3所示，JOSM是一个供使用者进行互动的开源OSM编辑器，你可以使用该编辑器来修改和更新OSM数据（josm.openstreetmap.de）。需要注意的是，JOSM是一个离线编辑器，即在用户上传到服务器之前，用户的所有操作和修改对于其他人都是不可见的。这可以让你在不修改服务器数据的情况下去尝试和反复移动、标记、添加和删除元素。在上传到服务器时，用户对单个元素进行的动作会在数据库中进行对应的修改。如果你想修改JOSM的功能，可以在<https://github.com/JOSM/josm>[2]中寻找其源码。

![图片](Aspose.Words.ab5bfc80-fed2-46a5-a0f5-8079ab04e10d.003.jpeg)

图8.3 JOSM用户界面

1. **增加一个节点或路**

我们可以尝试在OSM数据集中添加一个节点或者路。你既可以添加一个独立的节点，也可以在现有的路中添加，甚至可以在两条路交接处添加节点。下面是添加节点的方式，通过点击键盘上的“A”键来将其转换成“绘制节点”模式。将光标移动对应的区域。选择想要添加的空白区域、地图上的路或者GPS轨迹（GPS轨迹需要用户事先上传），然后左键想要放置的具体地点。此时，地图上会生成一个红点（此点为待选定的节点）并且该点与鼠标光标之间会通过一条可延伸的线相连接。如果你创建了新的节点，那么之前的节点会变成黄色的节点。多个节点之间会连接成一段路。

1. **增加标签**

在JOSM用户界面中添加标签如图8.4所示。我们在上述步骤中添加的节点和路只有当我们在其中添加了具体语义信息的标签才会有意义（地图功能页面中提供了一些常用的标签以供使用者快速选择）。

![图片](Aspose.Words.ab5bfc80-fed2-46a5-a0f5-8079ab04e10d.004.jpeg)

图8.4 在JOSM中添加一个标签

对节点和路添加标签的流程如下所示。首先我们需要确认JOSM右侧的“Tags/Membership”窗口是否处于打开状态。然后在该窗口中来编辑节点或路的具体属性（比如对其添加标签），需要注意的是，该窗口只可以编辑节点或者路。通过按下键盘上的“S”键来进入选择模式。点击你需要进行编辑的节点或者路，此时会跳出一个对话框，我们需要在该对话框中进行标签中键（Key）和值（Value）的选择。如果对给出的选择不满意，也可以自行键入对应标签的key/value对。例如，你可以将标签的键输入为 amenity（公共设施）并将对应的值输入为 fountain（喷泉）。最终点击确定按钮以完成标签的最终创建。我们也可以在JOSM中对一个目标添加多个标签。

1. **上传至OSM**

在完成对应地图区域所有的编辑工作之后，你就可以将其上传到OSM官网以对OSM社区做出贡献。如果你对于最终结果感到十分满意，即可将你的修改结果上传至OSM服务器上。点击上传按钮后，系统会自动对于你所做的修改进行验证。系统会查看所有的验证警告，并会在最终上传至服务器前对其进行修改和纠错。该机制可以有效的避免一些错误，例如出现未标记的对象或者未连接的路径。需要注意的是，验证器的警告不是绝对的。在特殊情况下，验证器的警告会是错误的。在上传之前，我们需要对添加一个合适的改变集合的注释，并对每个修改注明其来源。这一点十分重要，因为该注释会向所有使用者显示你对此进行修改的原因，并告知其该修改内容的来源。之后我们会在8.4节中展示如何使用JOSM来构建一个用于自动驾驶车辆的行驶地图。

**8.2.3 Nominatim**

Nominatim（来自拉丁语，意思是“名称”）是一个OSM工具，使用者可以通过具体名称和地址（地理编码）来寻找对应的OSM数据并且生成OSM点的合成地址（反向地理编码）。我们可以在nominatim.openstreetmap.org中找到含有最新数据的实例。Nominatim也被用在OSM首页的搜索工具栏中。同样的如果你需要对JOSM的功能进行一些修改，你可以在<https://github.com/osm-search/Nominatim>[3]中找到Nominatim的源码。

1. **Nominatim 架构**

Nominatim提供了一个基于OSM数据的地理编码。该工具使用PostgreSQL数据库作为存储数据的后端。Nominatim的架构存在三个基本部分：数据导入、地址计算和前端搜索。

在数据导入阶段，Nominatim需要读取原始OSM数据并提取出所有与地理编码相关的信息。在部分任务主要由osm2pgsql工具完成，我们也可以使用该工具来导入渲染数据库。

在地址计算和索引阶段，Nominatim需要从地点中获取其对应数据，并为其增加一些地理编码所需要的信息。Nominatim会对这些地点按照重要性进行排序，然后将属于同一个地点的对象联系起来，并计算地址和搜索索引。这部分工作主要在PostgreSQL中通过数据库触发器完成的。使用者可以在sql/functions.sql文件中查看对应源码。

Nominatim是一个开源的反向地理编码和搜索引擎，其前端搜索阶段是实现搜索和反向地理编码的关键步骤之一。在前端搜索阶段，Nominatim会构建应用程序接口，即API，来接收用户的搜索查询和反向地理编码查询请求。并将根据请求查找到的数据结果以请求的形式返回给用户。该部分功能是通过PHP实现的，使用者可以在lib/和site/目录下找到其源码。

1. **Nominatim对地点的排序**

Nominatim使用两个指标对地点进行排序：搜索排名(search rank)和地址排名(address rank)。两者取值都在0-30分之间，两个指标的用途略有不同。

搜索排名反应了该地点的范围和重要性，一般用于比较搜索结果。简单来说，如果一个搜索查询存在两个对应结果，且这两个结果在其他方面都是一样的，那么搜索排名较低的结果将在结果列表中出现在较高的位置。但是现在搜索等级的重要性在降低，现在很多知名地点的排名顺序已经被替换成维基百科中的重要性排名。

地址等级是用来描述地址在地址层次结构中所处位置的等级。一般来说，只有行政边界、地方节点和地区才有资格在地址中显示。其他对象的地址等级通常为0。需要注意的是，在计算地址时，搜索等级也会起到一定作用。在收集组成该部分地址的地点时，只会考虑地址等级低于该部分地址的地点。

当一个地点第一次被录入数据库时，我们会为其分配一个搜索等级和地址等级。一些硬编码的分配规则如下所示：

- 邮政编码需要根据其长度来遵循对应编码规则
- 边界不算是区域并且不可以使用railway=rail作为标签
- 以下情况的搜索等级是30，地址等级是0

`    `—高速公路节点

`    `—两个标志地点之间连接的道路

除此以外，我们可以过CONST\_ Address\_Level\_Config定义的json文件并根据其类型和所在国家自由分配不同的等级。

**8.3 高精地图**

高精地图可以为自动驾驶系统提供高精度、及时且全面的地理信息和驾驶环境的语义信息。自从2000年美国国防高级研究计划局提出构建高精地图的计划以来，高精地图已经广泛地被应用于自动驾驶车辆的精确定位中[4,5]。

除了定位，高精地图包含了用于感知、预测、运动规划和汽车控制所需的预计算数据(precomputed data)。一个预计算数据的经典实例就是交通灯的三维位置，该位置可以让自动驾驶车辆只检测一个小区域而不是对整个视野进行检查，从而可以更加有效的对交通灯进行检测。虽然对于能否在不使用事先建立的高精地图的情况下构建出一个完全自动驾驶系统的可能性仍存在很大争议，但是就目前为止，没有任何现有的高度自动驾驶系统(HAD)是在不使用某种高精地图的情况下就可以在城市环境中运行的。

**8.3.1 高精地图的特征**

**1.高精度**

顾名思义，能够应用于自动驾驶系统的高精地图，其需要有很高的精度，通常这个精度是需要达到厘米级的，虽然目前自动驾驶行业中没有一个具体精度的标准，但是通常认为高精地图的精度一般都在5厘米至20厘米之间。

**2.丰富的地理信息和语义信息**

高精地图中需要包含道路网络和周边环境的信息，同时尽可能全面的覆盖地理信息和语义信息，以用于定位、感知、预测运动规划和汽车控制。地图中最常见的内容包括车道/道路模型、交通控制设备(主要是交通灯和交通标志)的3D位置，以及其他静态道路元素的几何和语义，如路缘石（指的是设在路面边缘的界石，简称缘石，俗称路牙子。它是作为设置在路面边缘与其它构造带分界的条石）、人行道、铁路轨道、护栏、电线杆、公交车站、减速带、地面坑洞和立交桥。

**3.及时的数据**

高精地图需要及时更新地图数据变化。TomTom公司（是一家主营业务为地图、导航和GPS设备的荷兰公司，总部位于阿姆斯特丹）估计出美国每年有15%的道路会发生变化。虽然不是所有的变化都会影响到自动驾驶汽车的正常使用，但是我们可以通过这些变化来推断出我们需要对地图数据变化更新的数量级，以保证自动驾驶汽车在道路上的安全行驶。在自动驾驶领域中，我们需要每周都要对高精地图进行数据更新。相比之下，像谷歌地图之类的传统数字地图，其更新周期为6-12个月。因此自动驾驶高精地图的维护成本非常高，我们必须建立一个庞大的数据收集车队和一个十分重要的云计算基础设施来满足我们每周更新地图数据的要求。

**8.3.2 高精地图的图层**

高精地图通常由多个图层组成，这些图层协同作用来为自动驾驶车辆提供完整的信息。然而，考虑到多个图层可能导致高精地图过于庞大，自动驾驶系统一般从云端中获取地图[6,7]。在某些情况下，自动驾驶汽车也会下载附近环境的高精地图（也被称为子图）到车辆中。这些地图包含了车辆周围的道路、建筑物和其他重要的地标信息。子图的大小通常比完整的高精地图要小得多，因为它只包含了车辆附近的信息。这使得车辆能够快速获取所需的信息，并进行精确定位和路径规划。

高精地图的各个图层之间差异很大，每个图层都有不同的显示方式、不同的数据结构以及不同的作用。尽管对于高精地图，目前还没有一套标准的制作规则，但目前高精地图都会包含着以下四个图层。

1. **2D反射率地图**

反射率地图根据以下定理进行构建，即道路表面的不同材料（例如不同类型的路面材料、路标涂料等）具有不同的激光反射强度。该图层是一个从激光雷达（Light Detection and Ranging，LiDAR）点云中提取出的道路表面的2D平面图。通过在同一个区域进行多次扫描并将反射强度值纹理化到各点上，这会使得反射率地图看上去十分逼真。我们可以在《Map-based precision vehicle localization in urban environments》和《Automatic laser calibration, mapping, and localization for autonomous vehicles》两文[8,9]中寻找到反射率地图的可视化结果。

**2.数字高程模型**

数字高程模型（digital elevation model，DEM）是一个三维模型，该模型中包含了驾驶环境表面的高度信息，例如路边的高度、坡道或丘陵道路的坡度/陡度等。这部分要用于汽车的定位（在缺乏道路表面特征的情况下）、运动规划和车辆控制。我们可以在<https://medium.com/waymo/building-maps-for-a-self-driving-car-723b4d9cd3f4>链接中找到一个DEM可视化的实例。

1. **车道/道路模型**

车道/道路模型是高精地图中非常重要的矢量层，它包含了车道部分和道路部分的语义信息。车道模型仅包含车道内的信息，而道路模型包含了车道之外的道路信息。在自动驾驶汽车处于自动驾驶状态时，自动驾驶系统会优先处理车道模型，只有在极少数情况下才需要处理道路模型。因此，车道模型是自动驾驶系统中的关键组成部分。车道模型包括了车道的几何信息（如边界、宽度和曲率等）、车道类型（如汽车车道、自行车车道、公共汽车专用车道等）、车道方向信息、车道标记/分割线类型（如实现与虚线、单线与双线等）、车辆限制信息（如仅能左/右转）、车速限制以及车道之间的连接信息等。这些信息对于运动规划、车辆控制等方面的决策和操作是必不可少的。

**4.静态图层**

相较于上述三个图层，该图层没有一个精确的定义。其通常为一个多功能的图层，存储了许多其它层没有获取到的行驶环境周围的静态元素之间的语义信息（例如交通灯与其对应车道和道路障碍物之间的联系等）。

**8.3.3 高精地图的创建**

如图8.5所示，高精地图的创建存在以下四个阶段：数据收集、高精地图的生成、地图质量把控和验证、地图的更新和维护。

![图片](Aspose.Words.ab5bfc80-fed2-46a5-a0f5-8079ab04e10d.005.jpeg)

图 8.5 高精地图的创建（Data Collection：数据收集 Camera Imagery：相机图像 LiDAR Point Clouds：激光雷达点云 Wheel Odometry：轮式里程计 GPS：全球定位系统 

HD Map Generation：高精地图的生成  Sensor Fusion/Pose Estimation：传感器融合/姿态估计 Data Fusion/Data Processing：数据融合/数据处理 Object Location Detection：目标位置检测 Semantics/Attributes Extraction：语义信息/属性的提取

Quality Control and Validation：地图质量把控与验证

Update and Maintenance：地图的更新与维护）

**1.数据收集**

移动测绘系统（Mobile Mapping Systems，MMS）一般会配有多个传感器，例如激光雷达、相机、GPS、IMU（惯性测量单元）和轮速里程计等。一般MMS车辆会在对应道路地点进行实地考察和数据收集，将收集到的数据保存在固态硬盘设备中（或者将数据进行某种处理、过滤和压缩后，通过蜂窝网络将其上传到服务器或者云端中）。收集数据通常都是在一个城市的各个区域中进行的，该过程会涉及到合理的路径规划与高效的数据存储和传输。其中设备、人力、数据存储和传输的成本是在数据收集过程中最重要的几个问题。为此，如何减少数据冗余（对一段道路上的数据进行重复收集）成为了当下各大高校的研究者们非常感兴趣的一个研究方向。

为了创建一个高精地图我们需要收集以下两类数据：（1）高精地图数据：激光雷达点云和相机包含的环境的几何信息和语义信息，这些信息将会是构键高精地图的主要主体。（2）辅助数据：GPS/IMU/车轮里程表中的数据，该数据不包含环境的几何信息和语义信息，只能辅助前者来构建环境的高精地图。辅助数据主要用于优化数据采集车辆的位姿。 

**2.离线生成高精地图**

该部分工作主要在后台系统中进行，系统会处理收集到的数据并生成高精地图。数据处理大致可以进一步细分为以下四个步骤（如图8.5所示）。

①传感器融合/姿态估计：生成高精地图的关键在于能否获取MMS车辆的精确位置（包含了车辆位置和车辆方向）。如果我们不能获得汽车的精确位置，那么也就不可能生成精确的高精地图。一旦我们获取了到了数据采集车辆的精确位置，就可以结合传感器在车辆车架中的安装位置和其与车辆车架的相对角度，我们就可以计算出采集到的点云和图像在车辆中的精确位置。

由于GPS、IMU和轮式里程计等的限制，我们无法在车辆运行时直接获得其精确的位姿，但是我们可以通过离线优化（offline optimizations）来估计其精确的位姿，例如我们可以将不同传感器的数据作为因子图放入SLAM（同步定位与制图）中完成融合，从而来估算出车辆的精确位置[8，11]。

②地图数据的融合与处理：在处理地图数据的融合时，我们首先需要获取数据采集车的准确位姿。有了准确的位姿信息，我们就可以利用它来完成地图数据的融合与处理。地图数据主要包括通过雷达和相机采集到的点云和图像。需要注意的是，对于生成的高精地图，我们更关注视频的分辨率和质量，而不是视频的帧数。通常，我们使用的是高分辨率且帧数小于10的视频和图像。在数据融合过程中，我们会将多个扫描到的点云进行对齐和校准，以获得一个更加密集的点云。同时，点云与相机图像之间需要完成标定，这样我们就可以通过点云来获取图像中识别物体的三维位置，并在完成标定的图像中提取出对应物体的语义信息。之所以需要将点云和图像完成外参的标定，是因为点云只能提供物体精确的三维信息，而不能提供其对应的语义信息，而相机图像则与之相反，只能提供精确的语义信息。

此外，我们还需要对其他数据进行处理，使其尽可能地逼近真实图像。这包括生成道路平面、去除不相关物体和纹理（例如动态物体和离道路较远的物体）等。这样，我们可以为中文读者提供更加详实且易于理解的地图数据融合与处理内容。

③三维物体位置检测：对于那些几何形状和精确位置非常重要的道路元素（如车道边界、路缘石、交通信号灯、立交桥、铁轨、护栏、灯杆、减速带和坑洼地面），我们需要获取它们精确的三维位置信息。激光雷达点云可以提供物体精确的三维位置信息，我们可以通过几何学方法[12-15]和深度学习方法[16-18]来检测点云中的三维物体。此外，我们还可以不使用点云，而是通过对多张图片中出现的同一物体进行三角测量来检测三维物体的位置。例如，《Traffic light mapping and detection》[19]这篇文章就提出了一个这样的方法实例。

④语义信息/属性的提取：最后一步，也是工作量最大的一步，就是从数据中为高精度地图提取物体的语义信息和属性信息。这个过程包括车道/道路模型的构建、交通标志的识别、交通信号灯与车道的关联、道路标志语义信息的提取以及道路元素（如灯杆）的检测等。实际上，在生成大规模高精度地图之前，我们还需要进行其他准备工作，但上述几个步骤是最主要的。

**3.地图质量把控与验证**

自动驾驶汽车是一种无需人类驾驶员干预即可完成驾驶任务的汽车。这种汽车采用多种传感器，如激光雷达、毫米波雷达、摄像头和超声波传感器等，来感知周围环境，并通过预装在车内的电脑系统进行实时分析和处理，最终指挥车辆行驶。

**4.地图的更新与维护**

在该阶段，我们需要及时更新高精地图的数据，并修复其在使用过程中发现的各种问题。

**5.高精地图存在的问题**

虽然高精地图带来了诸多好处，但是建立高精地图所需复杂的步骤为其带来了一些问题。首先，我们需要部署大量的MMS车辆来收集地图的原始数据。这些数据收集车辆都配备有非常昂贵的传感器，例如激光雷达、高精度全球导航卫星系统（Global Navigation Satellite System，GNSS）、高清相机等。每辆MMS车的成本超过50万美元，这使得建立高精地图成本非常高。 其次，我们还需要部署一个功能非常强大的云计算基础设备以处理地图的原始数据并生成高精地图[7]。这些计算设备需要拥有高度的稳定性和可靠性，并且需要具备高速数据传输和存储能力，以满足高精地图数据的处理需求。这也意味着建立高精地图需要进行大量的投资和技术支持。 最后，由于高精地图需要每周都更新，因此高精地图供应商需要为此建立一个后勤团队，该团队需要不断扫描已经获取到数据的区域。与一般数字地图每6-12个月更新相比，高精地图的更新周期为一周，这给已经成本不菲的高精地图增加了额外的维护成本。因此，高精地图的建立和维护需要大量的资金和人力投入，这也是高精地图发展面临的挑战之一。

**8.4 PerceptIn公司的π-Map**

如上一节所示，高精地图的构建和维护成本极高，这使得其难以被大规模部署。但对于某些特定场景，例如在高度结构化的环境（例如大学校园、工业园区）中的低速（<20英里/小时）自动驾驶，我们可以通过扩展现有的数字地图来获取精确的车道信息以实现自动驾驶，而不是使用成熟的高精地图。在本节中，我们将以PerceptIn公司的地图技术为案例作为研究对象，该技术将现有的开源地图（数字地图）进行拓展以应用于智能机器人和自动驾驶汽车的导航中。

为了实现上述目标，PerceptIn公司开发了一种基于图形的数据结构来表示车道的拓扑结构，并采用一种仅使用实时动态（RTK）GNSS接收器[20]和JOSM工具链（可在https://josm.openstreetmap.de/中找到）来构建地图的方法。该地图被称为π-Map，可以轻松地与现有数字地图（如OSM）相结合，构建出一个双层地图。通过双层地图中提供的车道具体信息，规划和控制模块可以轻松规划出一条全局路线用于导航，同时生成一条局部路径规划和一系列控制命令，以控制自动驾驶车辆的行驶。

**8.4.1 拓扑图**

π-Map使用一组节点来表示道路的结构。虽然下面的模型仅用于说明，但在不影响地图正常使用的前提下，该模型是可行的。在这个模型中，一条道路可以包含一个或多个方向的车道，因此，自动驾驶车辆可以在车道上行驶。图8.6显示了一个由四个节点和四条边组成的简化地图模型。在实际应用中，节点是道路两侧的物理点，而节点之间的连线代表了它们之间的连接性。例如，节点0和节点1之间有一条连线，这意味着从节点0到节点1有一条可行的路径。

![图片](Aspose.Words.ab5bfc80-fed2-46a5-a0f5-8079ab04e10d.006.jpeg)

图8.6 地图拓扑图样例

π-Map使用以下数据结构来描述上述地图的拓扑结构。每一行表示一个节点，其中第一行包含节点0的信息，第二行包含节点1的信息，以此类推。每行的第一列和第二列分别表示对应节点的x坐标和y坐标（在通用横轴墨卡托坐标系下），而第三列则表示该节点相邻节点的数量（即与该节点相连的节点数），其余的列用于列出相邻节点的ID。

||第一列|第二列|第三列|第四列|第五列|
| :-: | :-: | :-: | :-: | :-: | :-: |
|第一行|X1|Y1|2|1|3|
|第二行|X2|Y2|2|0|2|
|第三行|X3|Y3|2|1|3|
|第四行|X4|Y4|2|2|0|

以第一行为例来对该数据结构进行说明

- 该行包含着节点0的具体信息
- 前两列的X1与Y1表示的是节点0的x坐标与y坐标
- 第三列的2表示的是相邻节点的数量
- 第四列和第五列的1和3是与节点0相邻的节点的ID

**8.4.2 π-Map的创建**

在本小节中，我们将介绍如何创建一个π-Map。如图8.7所示，我们以加州大学欧文分校的一部分区域为例，创建了一张食蚁兽娱乐中心(Anteater Recreation Center)周围道路的地图。

![图片](Aspose.Words.ab5bfc80-fed2-46a5-a0f5-8079ab04e10d.007.jpeg)

图 8.7 食蚁兽娱乐中心地图（实线表示我们创建的车道）

根据上一小节介绍的地图数据结构，我们需要通过节点的坐标和节点之间的连接信息来构建地图。在实际操作中，我们可以使用RTK GNSS接收器和JOSM来获得节点的坐标，并使用JOSM来绘制节点和节点间的连接线。

` `我们在食蚁兽娱乐中心(Anteater Recreation Center)周边创建了一个π-Map。如图8.8所示，我们通过以下步骤来实现该地图的构建。首先，在PerceptIn DragonFly Pod上安装RTK GNSS模块[21]。然后，我们驾驶DragonFly Pod沿着目标车道的中心行驶，使用RTK GNSS设备来获取汽车的轨迹信息。接着，将获取到的轨迹信息上传到JOSM中，并沿着汽车轨迹绘制节点。最终，我们使用JOSM来绘制节点与节点之间的连线。 

我们生成的地图由多个节点组成，表示该区域的拓扑结构。该拓扑结构被传入自动驾驶汽车的控制和规划模块，以实现简单的自动驾驶任务。例如，使用者可以通过在地图中任意点击来呼唤自动驾驶汽车，也可以通过在地图中选择新的目的地来设置自动驾驶的终点。![图片](Aspose.Words.ab5bfc80-fed2-46a5-a0f5-8079ab04e10d.008.jpeg)

图 8.8 JOSM中的地图结果

**参考文献**

1\**.**Jiao, J. (2018). Machine Learning assisted High-Definition Map creation. *2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)*, Tokyo, Japan (23–27 July 2018). IEEE.

2\**.**GitHub (2017). JOSM source code. <https://github.com/openstreetmap/josm> (accessed 1 December 2018).

3\.** GitHub (2017). Nominatim source code. <https://github.com/openstreetmap/Nominatim> (accessed 1 December 2018).

4 **.**Buehler, M., Iagnemma, K., and Singh, S. (eds.) (2007). *The 2005 DARPA Grand Challenge: The Great Robot Race*, vol. 36. Springer Science & Business Media.

5\**.** Buehler, M., Iagnemma, K., and Singh, S. (eds.) (2009). *The DARPA Urban Challenge: Autonomous Vehicles in City Traffic*, vol. 56. Springer.

6\**.** Liu, S., Li, L., Tang, J. et al. (2017). Creating autonomous vehicle systems. *Synthesis Lectures on Computer Science* 6 (1): 1–186.

.7Liu, S., Tang, J., Wang, C. et al. (2017). A unified cloud platform for autonomous driving.

**7.** Liu, S., Tang, J., Wang, C. et al. (2017). A unified cloud platform for autonomous driving.*Computer* 50 (12): 42–49.

8**     Levinson, J., Montemerlo, M., and Thrun, S. (2007). Map-based precision vehicle localization in urban environments. In: *Robotics: Science and Systems*, vol. 4, 1. MIT Press.

9\.Levinson, J. (2011). Automatic laser calibration, mapping, and localization for autonomous vehicles. PhD thesis. Stanford University.

10\.Waymo Team (2016). Building maps for a self-driving car. <https://medium.com/waymo/> building-maps-for-a-self-driving-car-723b4d9cd3f4 (accessed 1 June 2019).

11\.Thrun, S. and Montemerlo, M. (2006). The graph SLAM algorithm with applications to large-scale mapping of urban structures. *The International Journal of Robotics Research* 25 (5–6): 403–429.

12\.Yu, Y., Li, J., Guan, H. et al. (2015). Semiautomated extraction of street light poles from mobile LiDAR point-clouds. *IEEE Transactions on Geoscience and Remote Sensing* 53 (3): 1374–1386.

13\. Zheng, H., Wang, R., and Xu, S. (2017). Recognizing street lighting poles from mobile LiDAR data. *IEEE Transactions on Geoscience and Remote Sensing* 55 (1): 407–420.

14\. Ordóñez, C., Cabo, C., and Sanz-Ablanedo, E. (2017). Automatic detection and classification of pole-like objects for urban cartography using mobile laser scanning data. *Sensors* 17 (7): 1465.

15\.Fukano, K. and Masuda, H. (2015). Detection and classification of pole-like objects from mobile mapping data. *ISPRS Annals of Photogrammetry, Remote Sensing & Spatial Information Sciences*, La Grande Motte, France (28 September–3 October 2015). ISPRS.

16\.Qi, C.R., Su, H., Mo, K., and Guibas, L.J. (2017). PointNet: deep learning on point sets for 3D classification and segmentation. In: *Proceedings of Computer Vision and Pattern Recognition (CVPR)*, vol. 1, 4. IEEE.  

17\.Qi, C.R., Yi, L., Su, H., and Guibas, L.J. (2017). PointNet++: deep hierarchical feature learning on point sets in a metric space. In: *Advances in Neural Information Processing Systems*, 5105–5114. NeurIPS.

18\.Zhou, Y. and Tuzel, O. (2017). VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection. arXiv preprint arXiv:1711.06396.

19\.Fairfield, N. and Urmson, C. (2011). Traffic light mapping and detection. In: *2011 IEEE International Conference on Robotics and Automation (ICRA)*, 5421–5426. IEEE.

20\.PerceptIn (2018). PerceptIn DragonFly RTK GNSS Module. ht[tps://www](http://www.perceptin.io/).per[ceptin.io/](http://www.perceptin.io/) products (accessed 1 December 2018).

21\.Perceptin (2018). PerceptIn DragonFly Pod. ht[tps://www](http://www.perceptin.io/products).per[ceptin.io/products](http://www.perceptin.io/products) (accessed 1 December 2018).

